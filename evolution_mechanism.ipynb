{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import numba as nb\n",
        "from random import random, randint, shuffle, choices\n",
        "from numba import jit #acceleration\n",
        "from google.colab import files  #to download the text"
      ],
      "metadata": {
        "id": "xFw8l1FzA-JC"
      },
      "id": "xFw8l1FzA-JC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define functions"
      ],
      "metadata": {
        "id": "tZVpCmr84M7p"
      },
      "id": "tZVpCmr84M7p"
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True, parallel=True, fastmath=True, cache=True)\n",
        "def rand_sym(N_max, L):\n",
        "  '''\n",
        "  generate L*L random hollow symmetric matrices\n",
        "  '''\n",
        "  \n",
        "  Lambda_k = np.random.rand(N_max, L, L)\n",
        "  for C_ij in Lambda_k:\n",
        "    np.fill_diagonal(C_ij, 0)\n",
        "    C_ij += C_ij.T\n",
        "    C_ij /= 2\n",
        "\n",
        "  Lambda_d = [Lambda_k[0]]\n",
        "  \n",
        "  for i in range(1, N_max):\n",
        "    Lambda_d.append(Lambda_d[i - 1] + Lambda_k[i])\n",
        "  \n",
        "  return Lambda_d, Lambda_k\n",
        "\n",
        "def Choose_Prob_index(P):\n",
        "  '''\n",
        "  give a probability distribution P = [P1, P2, ..., PN], \n",
        "  choose one of then according to P and return the index (begin from 1)\n",
        "  '''\n",
        "\n",
        "  a = random()\n",
        "  P_index = 1\n",
        "  P_boundary = 0\n",
        "  for P_i in P:\n",
        "    P_boundary += P_i\n",
        "    if P_boundary > a:\n",
        "      return P_index\n",
        "    else:\n",
        "      P_index += 1\n",
        "  return P_index\n",
        "\n",
        "@jit(nopython=True, fastmath=True, cache=True)\n",
        "def Prob_Iq(q, Lambda_d, vec_N):\n",
        "  '''\n",
        "  In mode (I)\n",
        "  calcualte total FC vector for q and probaility that f_q using s_j\n",
        "  '''\n",
        "  tot_FC_q = [Lambda_d[ min(vec_N[q-1], vec_N[j]) -1 ][q-1][j] for j in range(q)]\n",
        "  \n",
        "  tot_Prob_I = 0\n",
        "  for i in tot_FC_q:\n",
        "    tot_Prob_I += i\n",
        "\n",
        "  Prob_I = [x/tot_Prob_I for x in tot_FC_q] #Prob_I(q, j)\n",
        "  \n",
        "  return Prob_I, tot_FC_q\n",
        "\n",
        "@jit(nopython=True, fastmath=True, cache=True)\n",
        "def h_p(p, freq):\n",
        "  '''\n",
        "  calculate h_p(B) based on the definition\n",
        "  '''\n",
        "\n",
        "  a = 0\n",
        "  for i in freq:\n",
        "    if i != 0: #lim_(x->0)(-x log x) = 0\n",
        "      a -= i * np.log(i)\n",
        "  return a/np.log(p)\n",
        "\n",
        "def total_effort(lam, h, p, q):\n",
        "  '''\n",
        "  calculate total effort\n",
        "  \n",
        "  ---paras\n",
        "  lam: system parameter\n",
        "  h: h_p(B)\n",
        "  p: size of Block inventory\n",
        "  q: size of Book\n",
        "  '''\n",
        "  return ( (1 - lam * (1 + np.log(p)/np.log(q) )) * h + (1 - lam)* q* np.log(q)/np.log(p) ) / q\n",
        "\n",
        "def I_ht(h0, freq_t, p):\n",
        "  '''\n",
        "  calculate h_p(B) at time t in mode (I)\n",
        "\n",
        "  freq_t is the frequency of selected block at time t\n",
        "  '''\n",
        "  \n",
        "  return h0 - (freq_t * np.log(freq_t) - (freq_t - 1) * np.log(freq_t - 1)) / np.log(p)\n",
        "\n",
        "@jit(nopython=True, fastmath=True, cache=True)\n",
        "def P_kq(z, k, q, Lambda_k, vec_N):\n",
        "  '''\n",
        "  return P_k used in mode (II)\n",
        "  '''\n",
        "  #ref: https://stackoverflow.com/questions/9987483/elif-in-list-comprehension-conditionals\n",
        "  weight_k = [Ck_qj if (vec_N[q-1] >= k) and (vec_N[j] >= k) else 0\n",
        "           for j, Ck_qj in enumerate(Lambda_k[k-1][q-1][:q-1])\n",
        "           ]\n",
        "  weight_k.append(z)\n",
        "\n",
        "  sum_weight_k = 0\n",
        "  for i in weight_k:\n",
        "    sum_weight_k += i\n",
        "\n",
        "  P_k = [n/sum_weight_k for n in weight_k]\n",
        "\n",
        "  return P_k\n",
        "\n",
        "@jit(nopython=True, fastmath=True, cache=True)\n",
        "def P_kj_mut(z, k, q, j, Lambda_k, vec_N):\n",
        "  '''\n",
        "  return P_k used in de novo like mutation\n",
        "\n",
        "  ---parameters\n",
        "  z: effective connection\n",
        "  k: k-th component, k = 1, ...\n",
        "  q: the Book length\n",
        "  j: j is a number in range(q)\n",
        "  \n",
        "  '''\n",
        "  #ref: https://stackoverflow.com/questions/9987483/elif-in-list-comprehension-conditionals\n",
        "  #Since C_jj =0, the de novo block can't use its original component to construct new block\n",
        "  weight_k = [Ck_ju if (vec_N[j] >= k) and (vec_N[u] >= k) else 0\n",
        "           for u, Ck_ju in enumerate(Lambda_k[k-1][j][:q])\n",
        "           ]\n",
        "  weight_k.append(z) #len(weight_k = q + 1)\n",
        "\n",
        "  sum_weight_k = 0\n",
        "  for i in weight_k:\n",
        "    sum_weight_k += i\n",
        "\n",
        "  P_k = [n/sum_weight_k for n in weight_k]\n",
        "\n",
        "  return P_k\n",
        "\n",
        "\n",
        "@jit(nopython=True, fastmath=True, cache=True)\n",
        "def U(n_1, n_2):\n",
        "  '''\n",
        "  generates a uniform random integer (not n_1) in the range [0, n_2 - 1]\n",
        "  '''\n",
        "  a = randint(0, n_2 - 2)\n",
        "  if a < n_1:\n",
        "    return a\n",
        "  elif a >= n_1:\n",
        "    return a + 1\n",
        "\n",
        "@jit(nopython=True, fastmath=True, cache=True)\n",
        "def mutation_list(q, p, P_mu):\n",
        "  '''\n",
        "  For all blocks in Book, they have the mutation probability P_mu.\n",
        "  When mutation happens, the block will be replaced by another block\n",
        "  This function is uniform mutation\n",
        "\n",
        "  ---paras\n",
        "  q: size of Book\n",
        "  p: size of Block inventory\n",
        "  P_mu: mutation probability\n",
        "  '''\n",
        "  m = [(j, U(j, p)) for j in range(q) if random() < P_mu]\n",
        "  return m\n",
        "\n",
        "@jit(nopython=True, fastmath=True, cache=True)\n",
        "def mutation_list_FC(q, B, P_mu, Prob_FC):\n",
        "  '''\n",
        "  For all blocks in Book, they have the mutation probability P_mu.\n",
        "  When mutation happens, the block will be replaced by another block\n",
        "  This function is non-uniform mutation (based on FC probability)\n",
        "\n",
        "  ---paras\n",
        "  q: size of Book\n",
        "  B: Block inventory\n",
        "  P_mu: mutation probability\n",
        "  Prob_FC: FC probability\n",
        "  '''\n",
        "  m = [(j, choices(B, weights = Prob_FC)[0]) for j in range(q) if random() < P_mu]\n",
        "  return m\n"
      ],
      "metadata": {
        "id": "x8zSI4IQfAem"
      },
      "id": "x8zSI4IQfAem",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define parameters and build FC network"
      ],
      "metadata": {
        "id": "xvffsNZE4XIZ"
      },
      "id": "xvffsNZE4XIZ"
    },
    {
      "cell_type": "code",
      "source": [
        "#define parameters (affect FC)\n",
        "L = 10000\n",
        "N_max = 5\n",
        "\n",
        "#build FC\n",
        "Lambda_d, Lambda_k = rand_sym(N_max, L)\n",
        "Lambda_d = np.array(Lambda_d)"
      ],
      "metadata": {
        "id": "YkTptHgBekEz"
      },
      "id": "YkTptHgBekEz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define parameters (not affect FC)\n",
        "P_N = np.array([0.15, 0.40, 0.25, 0.15, 0.05])\n",
        "lam = 0.47        #system parameter lambda\n",
        "z_cof = 0.004\n",
        "z = z_cof * L     #effective connection\n",
        "P_mu = 0.0005      #mutation probability\n",
        "T = 1             #repeat counts for mutation\n",
        "ini_num_Block = 3 #initial number of Blocks in Book\n",
        "#https://stackoverflow.com/questions/658763/how-to-suppress-scientific-notation-when-printing-float-values\n",
        "#the digit after decimal point is set to be 15\n",
        "name = f'{z_cof:.15f}'.rstrip('0').split('.')[1] + '_' + f'{lam:.15f}'.rstrip('0').split('.')[1]\n",
        "name = name + '_' + f'{P_mu:.15f}'.rstrip('0').split('.')[1] + '_' + str(T)"
      ],
      "metadata": {
        "id": "Rhx1TXhlQIoh"
      },
      "id": "Rhx1TXhlQIoh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The program in this section will generate the initial \"Book\".\n",
        "\n",
        "One should remind if the initial Book only contain one kind of block, there wil be `error`. \n",
        "\n",
        "When this *happens*, just run the following codes again. "
      ],
      "metadata": {
        "id": "bvPmt_w5eUhb"
      },
      "id": "bvPmt_w5eUhb"
    },
    {
      "cell_type": "code",
      "source": [
        "#restore information\n",
        "vec_N = np.array([Choose_Prob_index(P_N) for j in range(L)], dtype = int) #number of components\n",
        "#Book[j] = [j+1, c1, c2, ...], where ck is the component at position k\n",
        "Book = [[j+1] for j in range(L)] #Block[j] = Book[j][1:] = [c1, c2, ...]\n",
        "Block_inventory = [] #namely the set B = [Block[i]] (non-repeat)\n",
        "Block_freq = {} #frequency of Block appears in Book, format: {str(Block[i]): frequency}\n",
        "index_Block = {} #index in B, format: {str(Block[i]): index}\n",
        "Component_inventory = [0] #Component = 0,1,2,....\n",
        "Direction_count = [] #count Direction of evolution with 1: co-option, 2:de novo\n",
        "#count Direction of mutation with 0: reamin, 1: co-option like, 2:de novo like\n",
        "Direction_mut = []\n",
        "\n",
        "#total FC tensor = [C_1, C_2, ...], where C_i = [C_i1, C_i2, ...]\n",
        "tot_FC_list = [ [] for q in range(L)]\n",
        "for q in range(ini_num_Block):\n",
        "    tot_FC_list[q] = [Lambda_d[ min(vec_N[q-1], vec_N[j]) -1 ][q-1][j] for j in range(q)]\n",
        "\n",
        "\n",
        "#initialize begining blocks\n",
        "ib = -1 #index of block in B\n",
        "for j in range(ini_num_Block):\n",
        "  b = []\n",
        "  for i in range(vec_N[j]):\n",
        "    b.append(i)\n",
        "    if i > Component_inventory[-1]:\n",
        "      Component_inventory.append(i)\n",
        "  shuffle(b)\n",
        "  Book[j].extend(b)\n",
        "  str_b = str(b)\n",
        "  if str_b not in Block_freq:\n",
        "    ib += 1\n",
        "    index_Block[str_b] = ib\n",
        "    Block_freq[str_b] = 1\n",
        "    Block_inventory.append(b)\n",
        "  else:\n",
        "    Block_freq[str_b] += 1\n",
        "\n",
        "\n",
        "#initial effort\n",
        "h0 = 0\n",
        "p0 = len(Block_freq)\n",
        "q0 = ini_num_Block\n",
        "h0 = h_p(p0, np.fromiter(Block_freq.values(), dtype = int))\n",
        "\n",
        "print(Block_freq)\n",
        "print(Book)"
      ],
      "metadata": {
        "id": "qmJbAkEYQHRg"
      },
      "id": "qmJbAkEYQHRg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The main algorithm"
      ],
      "metadata": {
        "id": "N5yCeB_fcxs3"
      },
      "id": "N5yCeB_fcxs3"
    },
    {
      "cell_type": "code",
      "source": [
        "EFFORT = [] #record the effort after decide the direction of evolution\n",
        "mut_success = 0\n",
        "\n",
        "for t in range(1, L - q0 + 1):\n",
        "  '''\n",
        "  First part: decide the direction of evolution\n",
        "  '''\n",
        "  q = q0 + t\n",
        "\n",
        "  #mode (I) co-option\n",
        "  p0 = len(Block_freq)\n",
        "  Prob_I, tot_FC_list[q-1] = Prob_Iq(q, Lambda_d, vec_N) #Prob_I(q, j)\n",
        "  nu = Choose_Prob_index(Prob_I)\n",
        "\n",
        "  s_nu = Book[nu - 1][1:]\n",
        "  str_s_nu = str(s_nu)\n",
        "  index_nu = index_Block[str_s_nu]  \n",
        "\n",
        "  Bf_cooption = np.fromiter(Block_freq.values(), dtype = int)  \n",
        "  Bf_cooption[index_nu] += 1\n",
        "  h_0I = h_p(p0, Bf_cooption)\n",
        "  TF_I = total_effort(lam, h_0I, p0, q) #total effort in mode (I)\n",
        "\n",
        "  #mode (II) de novo\n",
        "  p = p0 + 1\n",
        "  b = []\n",
        "  II_compo = [Component_inventory[-1] + 1] #component list used in mode (II)\n",
        "  ini_len_II = 1\n",
        "  \n",
        "  #create new block\n",
        "  for k in range(1, vec_N[q-1] + 1):\n",
        "    \n",
        "    P_k = P_kq(z, k, q, Lambda_k, vec_N) #len(P_k) = q\n",
        "    j_k = Choose_Prob_index(P_k) #j_k <= q\n",
        "\n",
        "    if j_k == q:\n",
        "      #create new component\n",
        "      if ini_len_II != 1:\n",
        "        new_comp = II_compo[-1] + 1\n",
        "        II_compo.append(new_comp)\n",
        "      else:\n",
        "        new_comp = II_compo[-1]\n",
        "        ini_len_II += 1\n",
        "      b.append(new_comp)\n",
        "    else:\n",
        "      #used old component\n",
        "      b.append(Book[j_k - 1][k])\n",
        "\n",
        "\n",
        "  str_b = str(b)\n",
        "  Bf_denovo = np.fromiter(Block_freq.values(), dtype = int)\n",
        "\n",
        "  try:\n",
        "    #if we \"create\" an existing block\n",
        "    Bf_denovo[index_Block[str_b]] += 1\n",
        "    existing = True\n",
        "    h_0II = h_p(p0, Bf_denovo)\n",
        "    TF_II = total_effort(lam, h_0II, p0, q) #total effort in mode (II)\n",
        "\n",
        "  except:\n",
        "    #if we create a new block\n",
        "    existing = False\n",
        "    h_0II = h_p(p, Bf_denovo)\n",
        "    TF_II = total_effort(lam, h_0II, p, q) #total effort in mode (II)\n",
        "\n",
        "  #Principle of least effort\n",
        "  #decide the direction of evolution: (I) co-option or (II) de novo\n",
        "  \n",
        "\n",
        "  if TF_I >= TF_II: #choose de novo\n",
        "    Component_inventory.extend(II_compo)    \n",
        "\n",
        "    if existing: #de novo but using existing block\n",
        "      Block_freq[str_b] += 1\n",
        "      Direction_count.append(1.5)\n",
        "\n",
        "    else:\n",
        "      Block_freq[str_b] = 1\n",
        "      ib += 1\n",
        "      index_Block[str_b] = ib\n",
        "      #Block_inventory.append(b)\n",
        "      Direction_count.append(2)\n",
        "\n",
        "    Book[q-1].extend(b)\n",
        "    EFFORT.append(TF_II)\n",
        "\n",
        "  else: #choose co-option\n",
        "    Direction_count.append(1)\n",
        "    Block_freq[str_s_nu] += 1\n",
        "    Book[q-1].extend(s_nu)\n",
        "    vec_N[q-1] = vec_N[nu-1]\n",
        "    EFFORT.append(TF_I)\n",
        "  \n",
        "  '''\n",
        "  Second part: mutation\n",
        "  '''\n",
        "  \n",
        "  for mut_loop in range(T): #run mutation for T times\n",
        "\n",
        "    for j in range(q):\n",
        "      if random() <= P_mu:\n",
        "        str_s_j = str(Book[j][1:])\n",
        "        index_j = index_Block[str_s_j] #index of s_j in B\n",
        "        r_j = Block_freq[str_s_j] #original freq of s_j in B\n",
        "\n",
        "        #step1: decide the direction of evolution\n",
        "        ##(1) remain\n",
        "        Bfv = np.fromiter(Block_freq.values(), dtype = int)\n",
        "\n",
        "        h_old = h_p(p, Bfv)\n",
        "        TF_old = total_effort(lam, h_old, p, q)\n",
        "\n",
        "        ##(2) become existing (uniformly mutate s_j -> s_xi, co-option like)\n",
        "        xi = U(j, q)\n",
        "        str_s_xi = str(Book[xi][1:])\n",
        "        index_xi = index_Block[str_s_xi] #index of s_xi in B\n",
        "\n",
        "        if str_s_xi == str_s_j: #nothing changes\n",
        "          ht_I = h_p(p, Bfv)\n",
        "          TF_I = total_effort(lam, ht_I, p, q)\n",
        "\n",
        "        else: #s_j -> s_xi and str_s_xi != str_s_j\n",
        "          Bfv_cooption = Bfv.copy()\n",
        "          Bfv_cooption[index_j] -= 1\n",
        "          Bfv_cooption[index_xi] += 1\n",
        "\n",
        "          ht_I = h_p(p, Bfv_cooption)\n",
        "          TF_I = total_effort(lam, ht_I, p, q)\n",
        "        \n",
        "        ##(3) become new (s_j -> new block, de novo like)\n",
        "        Bfv_denovo = Bfv.copy()\n",
        "        Bfv_denovo[index_j] -= 1\n",
        "\n",
        "        if r_j == 1: #this situation does not affect size of B and effort\n",
        "          ht_II = h_old\n",
        "          TF_II = TF_old\n",
        "        elif r_j > 1:\n",
        "          ht_II = h_p(p + 1, Bfv_denovo)\n",
        "          TF_II = total_effort(lam, ht_II, p + 1, q)\n",
        "\n",
        "        #step3: principle of least effort\n",
        "        if (TF_old >= TF_I) and (TF_old >= TF_II):\n",
        "          #mutation successful\n",
        "          mut_success += 1\n",
        "\n",
        "          if TF_II > TF_I: #co-option like\n",
        "            EFFORT.append(TF_I)\n",
        "            \n",
        "            if str_s_j != str_s_xi:\n",
        "              Direction_mut.append(1)\n",
        "              Block_freq[str_s_j] -= 1\n",
        "              Block_freq[str_s_xi] += 1\n",
        "              Book[j][1:] = Book[xi][1:]\n",
        "              vec_N[j] = len(Book[xi][1:])\n",
        "            else:\n",
        "              Direction_mut.append(0.5)\n",
        "\n",
        "\n",
        "          else: #de novo like\n",
        "            EFFORT.append(TF_II)\n",
        "\n",
        "            if r_j == 1: #frequency one word becomes another frequency one\n",
        "              Direction_mut.append(1.5)\n",
        "              \n",
        "            elif r_j > 1:\n",
        "              Direction_mut.append(2)\n",
        "              the_same = True  #True when de novo word == existing word\n",
        "              \n",
        "              #\"while loop\" fits our need but it is too slow. Instead, we use \"for loop\".\n",
        "              for w in range(100000000000000000000):\n",
        "                if the_same == False:\n",
        "                  break\n",
        "                b_new = []\n",
        "                II_compo = [Component_inventory[-1] + 1] #components used in de novo\n",
        "                ini_len_II = 1\n",
        "\n",
        "                for k in range(1, vec_N[j] + 1):\n",
        "\n",
        "                  P_k = P_kj_mut(z, k, q, j, Lambda_k, vec_N) #len(P_k) == q+1\n",
        "                  mu_k = Choose_Prob_index(P_k) #mu_k <= q+1\n",
        "\n",
        "                  if mu_k == q + 1:\n",
        "                    #create new component\n",
        "                    if ini_len_II != 1:\n",
        "                      new_comp = II_compo[-1] + 1\n",
        "                      II_compo.append(new_comp)\n",
        "                    else:\n",
        "                      new_comp = II_compo[-1]\n",
        "                      ini_len_II += 1\n",
        "                    b_new.append(new_comp)\n",
        "                  else:\n",
        "                    #used old component\n",
        "                    b_new.append(Book[mu_k - 1][k])\n",
        "\n",
        "                str_b_new = str(b_new)\n",
        "                if str_b_new not in Block_freq:\n",
        "                  the_same = False\n",
        "              if the_same == True:\n",
        "                #after 100000000000000000000, the mutation still falses\n",
        "                raise ValueError(\"P_mu is too high to produce de novo like mutation, lower it.\")\n",
        "              \n",
        "              Book[j][1:] = b_new\n",
        "              Block_freq[str_s_j] -= 1\n",
        "              Block_freq[str_b_new] = 1\n",
        "              #Block_inventory.append(b_new)\n",
        "              Component_inventory.extend(II_compo)\n",
        "\n",
        "              p = p + 1 #new block change size of B\n",
        "              ib += 1   #B becomes larger\n",
        "              index_Block[str_b_new] = ib\n",
        "\n",
        "        elif (TF_I > TF_old) and (TF_II > TF_old): #remains old\n",
        "          Direction_mut.append(0)\n",
        "          EFFORT.append(TF_old)\n",
        "  \n",
        "  '''\n",
        "  Third part: before next iteration\n",
        "  '''\n",
        "  \n",
        "  B_freq_copy = Block_freq.copy()\n",
        "  index_Block = {}\n",
        "  ib = -1\n",
        "  #Block_inventory = []\n",
        "  for s_blk, freq in B_freq_copy.items():\n",
        "    #notice: s_blk is string\n",
        "    if freq != 0:\n",
        "      #Block_inventory.append(eval(s_blk)) #the eval can translate string to normal format\n",
        "      ib += 1\n",
        "      index_Block[s_blk] = ib\n",
        "    else:\n",
        "      del Block_freq[s_blk]"
      ],
      "metadata": {
        "id": "lwZnojnDFM5Y"
      },
      "id": "lwZnojnDFM5Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show result and save"
      ],
      "metadata": {
        "id": "UrQ6s_AddC6B"
      },
      "id": "UrQ6s_AddC6B"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Direction')\n",
        "plt.plot(Direction_count, '.', markersize = 2)\n",
        "plt.show()\n",
        "plt.title('Direction of mutation')\n",
        "plt.plot(Direction_mut, '.', markersize = 2)\n",
        "plt.show()\n",
        "plt.title('effort')\n",
        "plt.plot(EFFORT)\n",
        "plt.show()\n",
        "plt.title('FRD')\n",
        "rho = list(np.fromiter(Block_freq.values(),  dtype = int))\n",
        "rho.sort(reverse = True)\n",
        "rank = [i for i in range(len(rho))]\n",
        "plt.plot(rank, rho, '.')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S399rRtaaNBr"
      },
      "id": "S399rRtaaNBr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(name + '.txt', 'w')\n",
        "for wi in Book:\n",
        "  k = '-'.join(map(str, wi[1:]))\n",
        "  f.write(k)\n",
        "  f.write(' ')\n",
        "f.close()\n",
        "files.download(name + '.txt')"
      ],
      "metadata": {
        "id": "8n9zd1CaHXtP"
      },
      "id": "8n9zd1CaHXtP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}